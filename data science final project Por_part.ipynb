{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_por = pd.read_csv(\"student-por.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove G2 & G3 = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_por_2 = data_por.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_0 = data_por_2[data_por_2[\"G3\"]==0].index\n",
    "data_por_2 = data_por_2.drop(index = result_0)\n",
    "data_por_2 = data_por_2.reset_index()\n",
    "data_por_2 = data_por_2.drop(columns = [\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>home</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>home</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>634 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "629     MS   F   19       R     GT3       T     2     3  services     other   \n",
       "630     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
       "631     MS   F   18       U     GT3       T     1     1     other     other   \n",
       "632     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "633     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "\n",
       "     reason guardian  traveltime  studytime  failures schoolsup famsup paid  \\\n",
       "0    course   mother           2          2         0       yes     no   no   \n",
       "1    course   father           1          2         0        no    yes   no   \n",
       "2     other   mother           1          2         0       yes     no   no   \n",
       "3      home   mother           1          3         0        no    yes   no   \n",
       "4      home   father           1          2         0        no    yes   no   \n",
       "..      ...      ...         ...        ...       ...       ...    ...  ...   \n",
       "629  course   mother           1          3         1        no     no   no   \n",
       "630  course   mother           1          2         0        no    yes   no   \n",
       "631  course   mother           2          2         0        no     no   no   \n",
       "632  course   mother           2          1         0        no     no   no   \n",
       "633  course   mother           3          1         0        no     no   no   \n",
       "\n",
       "    activities nursery higher internet romantic  famrel  freetime  goout  \\\n",
       "0           no     yes    yes       no       no       4         3      4   \n",
       "1           no      no    yes      yes       no       5         3      3   \n",
       "2           no     yes    yes      yes       no       4         3      2   \n",
       "3          yes     yes    yes      yes      yes       3         2      2   \n",
       "4           no     yes    yes       no       no       4         3      2   \n",
       "..         ...     ...    ...      ...      ...     ...       ...    ...   \n",
       "629        yes      no    yes      yes       no       5         4      2   \n",
       "630         no     yes    yes      yes       no       4         3      4   \n",
       "631        yes     yes    yes       no       no       1         1      1   \n",
       "632         no      no    yes      yes       no       2         4      5   \n",
       "633         no      no    yes      yes       no       4         4      1   \n",
       "\n",
       "     Dalc  Walc  health  absences  G1  G2  G3  \n",
       "0       1     1       3         4   0  11  11  \n",
       "1       1     1       3         2   9  11  11  \n",
       "2       2     3       3         6  12  13  12  \n",
       "3       1     1       5         0  14  14  14  \n",
       "4       1     2       5         0  11  13  13  \n",
       "..    ...   ...     ...       ...  ..  ..  ..  \n",
       "629     1     2       5         4  10  11  10  \n",
       "630     1     1       1         4  15  15  16  \n",
       "631     1     1       5         6  11  12   9  \n",
       "632     3     4       2         6  10  10  10  \n",
       "633     3     4       5         4  10  11  11  \n",
       "\n",
       "[634 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_por_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.seed(5319)\n",
    "data_dict = data_por_2.to_dict(\"index\")\n",
    "data_dict_list = list(data_dict)\n",
    "test_index = rd.sample(data_dict_list, k = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_seperate(df_dict, index_list, test_list_index):\n",
    "    data_train = {}\n",
    "    data_test = {}\n",
    "    for i in range(len(index_list)):\n",
    "        if index_list[i] in test_list_index:\n",
    "            data_test[i] = df_dict[i]\n",
    "        else:\n",
    "            data_train[i] = df_dict[i]\n",
    "    data_train = pd.DataFrame.from_dict(data_train, orient = 'index')\n",
    "    data_test = pd.DataFrame.from_dict(data_test, orient = 'index')\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_seperate(data_dict, data_dict_list, test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categorical transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_transform(df):\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns = [\"index\"])\n",
    "    column_name = list(df.columns)\n",
    "    transform_dic = {}\n",
    "    for i in range(len(column_name)):\n",
    "        labelencoder = LabelEncoder()\n",
    "        if type(df[column_name[i]][1]) == str:\n",
    "            df[column_name[i]] = labelencoder.fit_transform(df[column_name[i]])\n",
    "            transform_dic[column_name[i]] = list(labelencoder.classes_)\n",
    "    return df, transform_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_2 = data_train.copy()\n",
    "data_train_2, categorical_dic = categorical_transform(data_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dalc</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>Medu</th>\n",
       "      <th>internet</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>paid</th>\n",
       "      <th>reason</th>\n",
       "      <th>sex</th>\n",
       "      <th>guardian</th>\n",
       "      <th>Walc</th>\n",
       "      <th>freetime</th>\n",
       "      <th>G2</th>\n",
       "      <th>activities</th>\n",
       "      <th>romantic</th>\n",
       "      <th>G3</th>\n",
       "      <th>higher</th>\n",
       "      <th>famsup</th>\n",
       "      <th>failures</th>\n",
       "      <th>absences</th>\n",
       "      <th>nursery</th>\n",
       "      <th>G1</th>\n",
       "      <th>school</th>\n",
       "      <th>health</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>goout</th>\n",
       "      <th>age</th>\n",
       "      <th>famrel</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>studytime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dalc  traveltime  Medu  internet  Fedu  paid  reason  sex  guardian  Walc  \\\n",
       "0     1           2     4         0     4     0       0    0         1     1   \n",
       "1     1           1     1         1     1     0       0    0         0     1   \n",
       "2     2           1     1         1     1     0       2    0         1     3   \n",
       "3     1           1     4         1     2     0       1    0         1     1   \n",
       "4     1           1     4         1     3     0       3    1         1     2   \n",
       "\n",
       "   freetime  G2  activities  romantic  G3  higher  famsup  failures  absences  \\\n",
       "0         3  11           0         0  11       1       0         0         4   \n",
       "1         3  11           0         0  11       1       1         0         2   \n",
       "2         3  13           0         0  12       1       0         0         6   \n",
       "3         2  14           1         1  14       1       1         0         0   \n",
       "4         4  12           1         0  13       1       1         0         6   \n",
       "\n",
       "   nursery  G1  school  health  Pstatus  goout  age  famrel  schoolsup  \\\n",
       "0        1   0       0       3        0      4   18       4          1   \n",
       "1        0   9       0       3        1      3   17       5          0   \n",
       "2        1  12       0       3        1      2   15       4          1   \n",
       "3        1  14       0       5        1      2   15       3          0   \n",
       "4        1  12       0       5        1      2   16       5          0   \n",
       "\n",
       "   address  famsize  Mjob  Fjob  studytime  \n",
       "0        1        0     0     4          2  \n",
       "1        1        0     0     2          2  \n",
       "2        1        1     0     2          2  \n",
       "3        1        0     1     3          3  \n",
       "4        1        1     3     2          2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pass or fail(based on result*60%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_to_pass_fail(data, total_mark, pass_percentage):\n",
    "    pass_fail = {}\n",
    "    if type(data) == pd.DataFrame:\n",
    "        for i in range(len(data)):\n",
    "            result_sum = sum(data.iloc[i])\n",
    "            if result_sum >= total_mark*pass_percentage:\n",
    "                pass_fail[i] = 1\n",
    "            else:\n",
    "                pass_fail[i] = 0\n",
    "    else:\n",
    "        for i in range(len(data)):\n",
    "            if data[i] >=  total_mark*pass_percentage:\n",
    "                pass_fail[i] = 1\n",
    "            else:\n",
    "                pass_fail[i] = 0\n",
    "    return pass_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result = data_train_2[[\"G1\", \"G2\", \"G3\"]]\n",
    "por_pass_fail = result_to_pass_fail(total_result, 60, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_2['pass_fail'] = por_pass_fail.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace 0 with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_num(df):\n",
    "    binary_data = df[[\"school\",\"sex\",\"address\",\"famsize\",\"Pstatus\",\"schoolsup\",\"famsup\",\"activities\",\"nursery\",\"higher\",\"internet\"]]\n",
    "    binary_data = binary_data.replace(0,-1)\n",
    "    df = df.drop(columns = [\"school\",\"sex\",\"address\",\"famsize\",\"Pstatus\",\"schoolsup\",\"famsup\",\"activities\",\"nursery\",\"higher\",\"internet\"])\n",
    "    df = pd.concat([df,binary_data], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_2 = replace_num(data_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randomforest and its result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.69        56\n",
      "           1       0.66      0.78      0.71        51\n",
      "\n",
      "    accuracy                           0.70       107\n",
      "   macro avg       0.71      0.70      0.70       107\n",
      "weighted avg       0.71      0.70      0.70       107\n",
      "\n",
      "[[35 11]\n",
      " [21 40]]\n"
     ]
    }
   ],
   "source": [
    "x = data_train_2.drop(columns = [\"G1\", \"G2\", \"G3\", \"pass_fail\"])\n",
    "y = data_train_2[\"pass_fail\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "randomforest_clf = RandomForestClassifier(n_estimators = 300, max_depth = 5)\n",
    "randomforest_clf.fit(train_x, train_y)\n",
    "pred_y = randomforest_clf.predict(test_x)\n",
    "print(classification_report(pred_y, test_y))\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71428571 0.77966102 0.72072072 0.66666667 0.11111111]\n",
      "0.5984890459466731\n"
     ]
    }
   ],
   "source": [
    "random_forest_cv = cross_validate(randomforest_clf, x, y, cv=5, scoring = 'f1')\n",
    "print(random_forest_cv['test_score'])\n",
    "print(np.mean(random_forest_cv['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_choosing(feature_importance, column_name, gate):\n",
    "    choosing_feature = {}\n",
    "    for i in range(len(feature_importance)):\n",
    "        if feature_importance[i] >= gate:\n",
    "            choosing_feature[column_name[i]] = feature_importance[i]\n",
    "    return choosing_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_importances = randomforest_clf.feature_importances_\n",
    "feature_name = list(x.columns)\n",
    "feature_choose = feature_importance_choosing(forest_importances, feature_name, 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.65      0.70        54\n",
      "           1       0.69      0.79      0.74        53\n",
      "\n",
      "    accuracy                           0.72       107\n",
      "   macro avg       0.72      0.72      0.72       107\n",
      "weighted avg       0.73      0.72      0.72       107\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[35, 11],\n",
       "       [19, 42]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data_train_2[feature_choose]\n",
    "y = data_train_2[\"pass_fail\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "randomforest_clf = RandomForestClassifier(n_estimators = 300, max_depth = 5)\n",
    "randomforest_clf.fit(train_x, train_y)\n",
    "pred_y = randomforest_clf.predict(test_x)\n",
    "print(classification_report(pred_y, test_y))\n",
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70422535 0.78333333 0.73043478 0.68421053 0.        ]\n",
      "0.5804407988740989\n"
     ]
    }
   ],
   "source": [
    "random_forest_cv = cross_validate(randomforest_clf, x, y, cv=5, scoring = 'f1')\n",
    "print(random_forest_cv['test_score'])\n",
    "print(np.mean(random_forest_cv['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting and its result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.69        56\n",
      "           1       0.66      0.78      0.71        51\n",
      "\n",
      "    accuracy                           0.70       107\n",
      "   macro avg       0.71      0.70      0.70       107\n",
      "weighted avg       0.71      0.70      0.70       107\n",
      "\n",
      "[[35 11]\n",
      " [21 40]]\n"
     ]
    }
   ],
   "source": [
    "x = data_train_2.drop(columns = [\"G1\", \"G2\", \"G3\", \"pass_fail\"])\n",
    "y = data_train_2[\"pass_fail\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "gradient_clf = GradientBoostingClassifier(learning_rate = 0.01, n_estimators = 1000, max_depth = 5, random_state = 1039)\n",
    "gradient_clf.fit(train_x, train_y)\n",
    "pred_y = gradient_clf.predict(test_x)\n",
    "print(classification_report(pred_y, test_y))\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67692308 0.73214286 0.61818182 0.66037736 0.20689655]\n",
      "0.5789043324924912\n"
     ]
    }
   ],
   "source": [
    "gradient_cv = cross_validate(gradient_clf, x, y, cv=5, scoring = 'f1')\n",
    "print(gradient_cv['test_score'])\n",
    "print(np.mean(gradient_cv['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_importances = gradient_clf.feature_importances_\n",
    "feature_name = list(x.columns)\n",
    "feature_choose_gradient = feature_importance_choosing(gradient_importances, feature_name, 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.62      0.70        60\n",
      "           1       0.62      0.81      0.70        47\n",
      "\n",
      "    accuracy                           0.70       107\n",
      "   macro avg       0.71      0.71      0.70       107\n",
      "weighted avg       0.72      0.70      0.70       107\n",
      "\n",
      "[[37  9]\n",
      " [23 38]]\n"
     ]
    }
   ],
   "source": [
    "x = data_train_2[feature_choose_gradient]\n",
    "y = data_train_2[\"pass_fail\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "gradient_clf = GradientBoostingClassifier(learning_rate = 0.01, n_estimators = 1000, max_depth = 5, random_state = 1039)\n",
    "gradient_clf.fit(train_x, train_y)\n",
    "pred_y = gradient_clf.predict(test_x)\n",
    "print(classification_report(pred_y, test_y))\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.69158879 0.7079646  0.69026549 0.1754386 ]\n",
      "0.5863848273400398\n"
     ]
    }
   ],
   "source": [
    "gradient_cv = cross_validate(gradient_clf, x, y, cv=5, scoring = 'f1')\n",
    "print(gradient_cv['test_score'])\n",
    "print(np.mean(gradient_cv['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting and its result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yang\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\xgboost\\__init__.py:29: FutureWarning: Python 3.5 support is deprecated; XGBoost will require Python 3.6+ in the near future. Consider upgrading to Python 3.6+.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65        49\n",
      "           1       0.70      0.74      0.72        58\n",
      "\n",
      "    accuracy                           0.69       107\n",
      "   macro avg       0.69      0.69      0.69       107\n",
      "weighted avg       0.69      0.69      0.69       107\n",
      "\n",
      "[[31 15]\n",
      " [18 43]]\n"
     ]
    }
   ],
   "source": [
    "x = data_train_2.drop(columns = [\"G1\", \"G2\", \"G3\", \"pass_fail\"])\n",
    "y = data_train_2[\"pass_fail\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "xgb_clf = XGBClassifier(learning_rate = 0.01, alpha = 0.1, max_depth = 8)\n",
    "xgb_clf.fit(train_x, train_y)\n",
    "pred_y = xgb_clf.predict(test_x)\n",
    "print(classification_report(pred_y, test_y))\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69565217 0.7027027  0.72072072 0.72       0.13793103]\n",
      "0.595401326363845\n"
     ]
    }
   ],
   "source": [
    "xgb_cv = cross_validate(xgb_clf, x, y, cv=5, scoring = 'f1')\n",
    "print(xgb_cv['test_score'])\n",
    "print(np.mean(xgb_cv['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_importances = xgb_clf.feature_importances_\n",
    "feature_name = list(x.columns)\n",
    "feature_choose_xgb = feature_importance_choosing(xgb_importances, feature_name, 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58        43\n",
      "           1       0.72      0.69      0.70        64\n",
      "\n",
      "    accuracy                           0.65       107\n",
      "   macro avg       0.64      0.65      0.64       107\n",
      "weighted avg       0.66      0.65      0.66       107\n",
      "\n",
      "[[26 20]\n",
      " [17 44]]\n"
     ]
    }
   ],
   "source": [
    "x = data_train_2[feature_choose_xgb]\n",
    "y = data_train_2[\"pass_fail\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "xgb_clf = XGBClassifier(learning_rate = 0.01, alpha = 0.1, max_depth = 8)\n",
    "xgb_clf.fit(train_x, train_y)\n",
    "pred_y = xgb_clf.predict(test_x)\n",
    "print(classification_report(pred_y, test_y))\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68571429 0.77586207 0.77310924 0.68421053 0.        ]\n",
      "0.5837792249386142\n"
     ]
    }
   ],
   "source": [
    "xgb_cv = cross_validate(xgb_clf, x, y, cv=5, scoring = 'f1')\n",
    "print(xgb_cv['test_score'])\n",
    "print(np.mean(xgb_cv['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model feature choose compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_feature = pd.DataFrame(feature_choose.values(), index = feature_choose.keys(), columns = ['RandomForest_clf'])\n",
    "gradient_feature = pd.DataFrame(feature_choose_gradient.values(), index = feature_choose_gradient.keys(), columns = ['GradientBoosting_clf'])\n",
    "XGB_feature = pd.DataFrame(feature_choose_xgb.values(), index = feature_choose_xgb.keys(), columns = ['XGBoosting_clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yang\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest_clf</th>\n",
       "      <th>GradientBoosting_clf</th>\n",
       "      <th>XGBoosting_clf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dalc</th>\n",
       "      <td>0.037187</td>\n",
       "      <td>0.031865</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fedu</th>\n",
       "      <td>0.038267</td>\n",
       "      <td>0.037250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medu</th>\n",
       "      <td>0.044315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob</th>\n",
       "      <td>0.033608</td>\n",
       "      <td>0.042173</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walc</th>\n",
       "      <td>0.050030</td>\n",
       "      <td>0.042928</td>\n",
       "      <td>0.038061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absences</th>\n",
       "      <td>0.077664</td>\n",
       "      <td>0.098264</td>\n",
       "      <td>0.036358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.042519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.039930</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures</th>\n",
       "      <td>0.168967</td>\n",
       "      <td>0.155024</td>\n",
       "      <td>0.269781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famrel</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043363</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034898</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044416</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher</th>\n",
       "      <td>0.079551</td>\n",
       "      <td>0.050380</td>\n",
       "      <td>0.089187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041128</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>0.064824</td>\n",
       "      <td>0.041808</td>\n",
       "      <td>0.073595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime</th>\n",
       "      <td>0.064011</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RandomForest_clf  GradientBoosting_clf  XGBoosting_clf\n",
       "Dalc               0.037187              0.031865        0.000000\n",
       "Fedu               0.038267              0.037250        0.000000\n",
       "Medu               0.044315              0.000000        0.000000\n",
       "Mjob               0.033608              0.042173        0.000000\n",
       "Walc               0.050030              0.042928        0.038061\n",
       "absences           0.077664              0.098264        0.036358\n",
       "address            0.042519              0.000000        0.000000\n",
       "age                0.030596              0.039930        0.000000\n",
       "failures           0.168967              0.155024        0.269781\n",
       "famrel             0.000000              0.043363        0.000000\n",
       "goout              0.000000              0.034898        0.000000\n",
       "health             0.000000              0.044416        0.000000\n",
       "higher             0.079551              0.050380        0.089187\n",
       "paid               0.000000              0.000000        0.038239\n",
       "reason             0.000000              0.041128        0.000000\n",
       "school             0.064824              0.041808        0.073595\n",
       "schoolsup          0.000000              0.000000        0.041681\n",
       "studytime          0.064011              0.041000        0.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_choose_compare = pd.concat([forest_feature,gradient_feature,XGB_feature],axis = 1)\n",
    "feature_choose_compare = feature_choose_compare.fillna(0)\n",
    "feature_choose_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    df, a = categorical_transform(df)\n",
    "    test_result = df[[\"G1\", \"G2\", \"G3\"]]\n",
    "    test_pass_fail = result_to_pass_fail(test_result, 60, 0.6)\n",
    "    df['pass_fail'] = test_pass_fail.values()\n",
    "    df = replace_num(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_2 = data_preprocessing(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.70        51\n",
      "           1       0.70      0.65      0.67        49\n",
      "\n",
      "    accuracy                           0.69       100\n",
      "   macro avg       0.69      0.69      0.69       100\n",
      "weighted avg       0.69      0.69      0.69       100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[37, 17],\n",
       "       [14, 32]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data_train_2[feature_choose]\n",
    "y = data_train_2[\"pass_fail\"]\n",
    "test_x = data_test_2[feature_choose]\n",
    "test_y = data_test_2[\"pass_fail\"]\n",
    "randomforest_clf = RandomForestClassifier(n_estimators = 300, max_depth = 5)\n",
    "randomforest_clf.fit(x, y)\n",
    "pred_y = randomforest_clf.predict(test_x)\n",
    "print(classification_report(pred_y, test_y))\n",
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67        53\n",
      "           1       0.63      0.62      0.62        47\n",
      "\n",
      "    accuracy                           0.65       100\n",
      "   macro avg       0.65      0.65      0.65       100\n",
      "weighted avg       0.65      0.65      0.65       100\n",
      "\n",
      "[[36 18]\n",
      " [17 29]]\n"
     ]
    }
   ],
   "source": [
    "x = data_train_2[feature_choose_gradient]\n",
    "y = data_train_2[\"pass_fail\"]\n",
    "test_x = data_test_2[feature_choose_gradient]\n",
    "test_y = data_test_2[\"pass_fail\"]\n",
    "gradient_clf = GradientBoostingClassifier(learning_rate = 0.01, n_estimators = 1000, max_depth = 5, random_state = 1039)\n",
    "gradient_clf.fit(x, y)\n",
    "pred_y = gradient_clf.predict(test_x)\n",
    "print(classification_report(pred_y, test_y))\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.69        50\n",
      "           1       0.70      0.64      0.67        50\n",
      "\n",
      "    accuracy                           0.68       100\n",
      "   macro avg       0.68      0.68      0.68       100\n",
      "weighted avg       0.68      0.68      0.68       100\n",
      "\n",
      "[[36 18]\n",
      " [14 32]]\n"
     ]
    }
   ],
   "source": [
    "x = data_train_2[feature_choose_xgb]\n",
    "y = data_train_2[\"pass_fail\"]\n",
    "test_x = data_test_2[feature_choose_xgb]\n",
    "test_y = data_test_2[\"pass_fail\"]\n",
    "xgb_clf = XGBClassifier(learning_rate = 0.01, alpha = 0.1, max_depth = 5)\n",
    "xgb_clf.fit(x, y)\n",
    "pred_y = xgb_clf.predict(test_x)\n",
    "print(classification_report(pred_y, test_y))\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rd.seed(8719)\n",
    "data_dict_2 = data_por_2.to_dict(\"index\")\n",
    "data_dict_list_2 = list(data_dict_2)\n",
    "test_index_2 = rd.sample(data_dict_list_2, k = 100)\n",
    "data_reg_train, data_reg_test = train_test_seperate(data_dict_2, data_dict_list_2, test_index_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_reg_2 = data_preprocessing(data_reg_train)\n",
    "data_test_reg_2 = data_preprocessing(data_reg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient boosting regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5312579705167\n",
      "2.5556325969349936\n",
      "0.14249245998433857\n"
     ]
    }
   ],
   "source": [
    "x = data_train_reg_2.drop(columns = [\"G1\", \"G2\", \"G3\", \"pass_fail\"])\n",
    "y = data_train_reg_2[\"G3\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "grad_regression = GradientBoostingRegressor(learning_rate = 0.01, n_estimators = 1000, max_depth = 5)\n",
    "grad_regression.fit(train_x, train_y)\n",
    "grad_pred_y = grad_regression.predict(test_x)\n",
    "print(mean_squared_error(test_y, grad_pred_y))\n",
    "print(math.sqrt(mean_squared_error(test_y, grad_pred_y)))\n",
    "print(r2_score(test_y, grad_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.06935035 5.56948829 5.90695478 5.22966743 7.9990195 ]\n",
      "5.754896072183358\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(grad_regression, x, y, cv=5, scoring = 'neg_mean_squared_error')\n",
    "print(-cv_results['test_score'])\n",
    "print(-np.mean(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_importances_2 = grad_regression.feature_importances_\n",
    "feature_name = list(x.columns)\n",
    "feature_choose_gradient_2 = feature_importance_choosing(gradient_importances_2, feature_name, 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.9040238687467275\n",
      "2.627550926004428\n",
      "0.0935509590000081\n"
     ]
    }
   ],
   "source": [
    "x = data_train_reg_2[feature_choose_gradient_2]\n",
    "y = data_train_reg_2[\"G3\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "grad_regression = GradientBoostingRegressor(learning_rate = 0.01, n_estimators = 1000, max_depth =5)\n",
    "grad_regression.fit(train_x, train_y)\n",
    "grad_pred_y = grad_regression.predict(test_x)\n",
    "print(mean_squared_error(test_y, grad_pred_y))\n",
    "print(math.sqrt(mean_squared_error(test_y, grad_pred_y)))\n",
    "print(r2_score(test_y, grad_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.94363687 6.14622619 7.00426041 4.85226474 7.91381068]\n",
      "6.172039778677613\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(grad_regression, x, y, cv=5, scoring = 'neg_mean_squared_error')\n",
    "print(-cv_results['test_score'])\n",
    "print(-np.mean(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.051263427965643\n",
      "2.459931590098725\n",
      "0.20551231638289658\n"
     ]
    }
   ],
   "source": [
    "x = data_train_reg_2.drop(columns = [\"G1\", \"G2\", \"G3\", \"pass_fail\"])\n",
    "y = data_train_reg_2[\"G3\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "random_regression = RandomForestRegressor(max_depth = 5, n_estimators = 300)\n",
    "random_regression.fit(train_x, train_y)\n",
    "random_pred_y = random_regression.predict(test_x)\n",
    "print(mean_squared_error(test_y, random_pred_y))\n",
    "print(math.sqrt(mean_squared_error(test_y, random_pred_y)))\n",
    "print(r2_score(test_y, random_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.9290665  5.03658881 6.10572448 4.05238272 7.60959109]\n",
      "5.346670718623425\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(random_regression, x, y, cv=5, scoring = 'neg_mean_squared_error')\n",
    "print(-cv_results['test_score'])\n",
    "print(-np.mean(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_importances_2 = random_regression.feature_importances_\n",
    "feature_name = list(x.columns)\n",
    "feature_choose_forest_2 = feature_importance_choosing(forest_importances_2, feature_name, 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.23468389983181\n",
      "2.496934900999986\n",
      "0.18143051800217413\n"
     ]
    }
   ],
   "source": [
    "x = data_train_reg_2[feature_choose_forest_2]\n",
    "y = data_train_reg_2[\"G3\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "random_regression = RandomForestRegressor(max_depth = 5, n_estimators = 300)\n",
    "random_regression.fit(train_x, train_y)\n",
    "random_pred_y = random_regression.predict(test_x)\n",
    "print(mean_squared_error(test_y, random_pred_y))\n",
    "print(math.sqrt(mean_squared_error(test_y, random_pred_y)))\n",
    "print(r2_score(test_y, random_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.76933244 5.11465382 6.25858068 4.29748698 7.21392094]\n",
      "5.330794971792481\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(random_regression, x, y, cv=5, scoring = 'neg_mean_squared_error')\n",
    "print(-cv_results['test_score'])\n",
    "print(-np.mean(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor and its result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.486796795932808\n",
      "4.846317859564394\n",
      "-2.083648729577702\n"
     ]
    }
   ],
   "source": [
    "x = data_train_reg_2.drop(columns = [\"G1\", \"G2\", \"G3\", \"pass_fail\"])\n",
    "y = data_train_reg_2[\"G3\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "xgb_regression = XGBRegressor(learning_rate = 0.01, alpha = 0.1, max_depth = 5)\n",
    "xgb_regression.fit(train_x, train_y)\n",
    "xgb_pred_y = xgb_regression.predict(test_x)\n",
    "print(mean_squared_error(test_y, xgb_pred_y))\n",
    "print(math.sqrt(mean_squared_error(test_y, xgb_pred_y)))\n",
    "print(r2_score(test_y, xgb_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.20885412 20.66711204 31.59990236 26.6074362  22.81065121]\n",
      "24.778791183872354\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(xgb_regression, x, y, cv=5, scoring = 'neg_mean_squared_error')\n",
    "print(-cv_results['test_score'])\n",
    "print(-np.mean(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_importances_2 = xgb_regression.feature_importances_\n",
    "feature_name = list(x.columns)\n",
    "feature_choose_xgb_2 = feature_importance_choosing(xgb_importances_2, feature_name, 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.578732276950635\n",
      "4.855793681464507\n",
      "-2.0957192018394974\n"
     ]
    }
   ],
   "source": [
    "x = data_train_reg_2[feature_choose_xgb_2]\n",
    "y = data_train_reg_2[\"G3\"]\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 1039)\n",
    "xgb_regression = XGBRegressor(learning_rate = 0.01, alpha = 0.1, max_depth = 5)\n",
    "xgb_regression.fit(train_x, train_y)\n",
    "xgb_pred_y = xgb_regression.predict(test_x)\n",
    "print(mean_squared_error(test_y, xgb_pred_y))\n",
    "print(math.sqrt(mean_squared_error(test_y, xgb_pred_y)))\n",
    "print(r2_score(test_y, xgb_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.89012429 21.98327498 33.2871599  25.82920063 21.2226296 ]\n",
      "24.44247787990366\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(xgb_regression, x, y, cv=5, scoring = 'neg_mean_squared_error')\n",
    "print(-cv_results['test_score'])\n",
    "print(-np.mean(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_feature_2 = pd.DataFrame(random_regression.feature_importances_, index = feature_choose_forest_2.keys(), columns = ['RandomForest_reg'])\n",
    "gradient_feature_2 = pd.DataFrame(grad_regression.feature_importances_, index = feature_choose_gradient_2.keys(), columns = ['GradientBoosting_reg'])\n",
    "XGB_feature_2 = pd.DataFrame(xgb_regression.feature_importances_, index = feature_choose_xgb_2.keys(), columns = ['XGBoosting_reg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yang\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest_reg</th>\n",
       "      <th>GradientBoosting_reg</th>\n",
       "      <th>XGBoosting_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dalc</th>\n",
       "      <td>0.057245</td>\n",
       "      <td>0.056095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fedu</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medu</th>\n",
       "      <td>0.106456</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.042016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walc</th>\n",
       "      <td>0.055942</td>\n",
       "      <td>0.051430</td>\n",
       "      <td>0.026803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absences</th>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.101589</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.126148</td>\n",
       "      <td>0.084521</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures</th>\n",
       "      <td>0.322562</td>\n",
       "      <td>0.202105</td>\n",
       "      <td>0.640623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065369</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063777</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher</th>\n",
       "      <td>0.179186</td>\n",
       "      <td>0.090259</td>\n",
       "      <td>0.210406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime</th>\n",
       "      <td>0.062394</td>\n",
       "      <td>0.071769</td>\n",
       "      <td>0.041594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RandomForest_reg  GradientBoosting_reg  XGBoosting_reg\n",
       "Dalc               0.057245              0.056095        0.000000\n",
       "Fedu               0.000000              0.061460        0.000000\n",
       "Fjob               0.000000              0.052211        0.000000\n",
       "Medu               0.106456              0.099415        0.042016\n",
       "Walc               0.055942              0.051430        0.026803\n",
       "absences           0.090067              0.101589        0.000000\n",
       "address            0.000000              0.000000        0.021665\n",
       "age                0.126148              0.084521        0.000000\n",
       "failures           0.322562              0.202105        0.640623\n",
       "goout              0.000000              0.065369        0.000000\n",
       "guardian           0.000000              0.000000        0.016892\n",
       "health             0.000000              0.063777        0.000000\n",
       "higher             0.179186              0.090259        0.210406\n",
       "studytime          0.062394              0.071769        0.041594"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_choose_compare_2 = pd.concat([forest_feature_2,gradient_feature_2,XGB_feature_2],axis = 1)\n",
    "feature_choose_compare_2 = feature_choose_compare_2.fillna(0)\n",
    "feature_choose_compare_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor and Classifier compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yang\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest_reg</th>\n",
       "      <th>GradientBoosting_reg</th>\n",
       "      <th>XGBoosting_reg</th>\n",
       "      <th>RandomForest_clf</th>\n",
       "      <th>GradientBoosting_clf</th>\n",
       "      <th>XGBoosting_clf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dalc</th>\n",
       "      <td>0.057245</td>\n",
       "      <td>0.056095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037187</td>\n",
       "      <td>0.031865</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fedu</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038267</td>\n",
       "      <td>0.037250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medu</th>\n",
       "      <td>0.106456</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.042016</td>\n",
       "      <td>0.044315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033608</td>\n",
       "      <td>0.042173</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walc</th>\n",
       "      <td>0.055942</td>\n",
       "      <td>0.051430</td>\n",
       "      <td>0.026803</td>\n",
       "      <td>0.050030</td>\n",
       "      <td>0.042928</td>\n",
       "      <td>0.038061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absences</th>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.101589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077664</td>\n",
       "      <td>0.098264</td>\n",
       "      <td>0.036358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021665</td>\n",
       "      <td>0.042519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.126148</td>\n",
       "      <td>0.084521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.039930</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures</th>\n",
       "      <td>0.322562</td>\n",
       "      <td>0.202105</td>\n",
       "      <td>0.640623</td>\n",
       "      <td>0.168967</td>\n",
       "      <td>0.155024</td>\n",
       "      <td>0.269781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famrel</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043363</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034898</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044416</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher</th>\n",
       "      <td>0.179186</td>\n",
       "      <td>0.090259</td>\n",
       "      <td>0.210406</td>\n",
       "      <td>0.079551</td>\n",
       "      <td>0.050380</td>\n",
       "      <td>0.089187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041128</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064824</td>\n",
       "      <td>0.041808</td>\n",
       "      <td>0.073595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime</th>\n",
       "      <td>0.062394</td>\n",
       "      <td>0.071769</td>\n",
       "      <td>0.041594</td>\n",
       "      <td>0.064011</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RandomForest_reg  GradientBoosting_reg  XGBoosting_reg  \\\n",
       "Dalc               0.057245              0.056095        0.000000   \n",
       "Fedu               0.000000              0.061460        0.000000   \n",
       "Fjob               0.000000              0.052211        0.000000   \n",
       "Medu               0.106456              0.099415        0.042016   \n",
       "Mjob                    NaN                   NaN             NaN   \n",
       "Walc               0.055942              0.051430        0.026803   \n",
       "absences           0.090067              0.101589        0.000000   \n",
       "address            0.000000              0.000000        0.021665   \n",
       "age                0.126148              0.084521        0.000000   \n",
       "failures           0.322562              0.202105        0.640623   \n",
       "famrel                  NaN                   NaN             NaN   \n",
       "goout              0.000000              0.065369        0.000000   \n",
       "guardian           0.000000              0.000000        0.016892   \n",
       "health             0.000000              0.063777        0.000000   \n",
       "higher             0.179186              0.090259        0.210406   \n",
       "paid                    NaN                   NaN             NaN   \n",
       "reason                  NaN                   NaN             NaN   \n",
       "school                  NaN                   NaN             NaN   \n",
       "schoolsup               NaN                   NaN             NaN   \n",
       "studytime          0.062394              0.071769        0.041594   \n",
       "\n",
       "           RandomForest_clf  GradientBoosting_clf  XGBoosting_clf  \n",
       "Dalc               0.037187              0.031865        0.000000  \n",
       "Fedu               0.038267              0.037250        0.000000  \n",
       "Fjob                    NaN                   NaN             NaN  \n",
       "Medu               0.044315              0.000000        0.000000  \n",
       "Mjob               0.033608              0.042173        0.000000  \n",
       "Walc               0.050030              0.042928        0.038061  \n",
       "absences           0.077664              0.098264        0.036358  \n",
       "address            0.042519              0.000000        0.000000  \n",
       "age                0.030596              0.039930        0.000000  \n",
       "failures           0.168967              0.155024        0.269781  \n",
       "famrel             0.000000              0.043363        0.000000  \n",
       "goout              0.000000              0.034898        0.000000  \n",
       "guardian                NaN                   NaN             NaN  \n",
       "health             0.000000              0.044416        0.000000  \n",
       "higher             0.079551              0.050380        0.089187  \n",
       "paid               0.000000              0.000000        0.038239  \n",
       "reason             0.000000              0.041128        0.000000  \n",
       "school             0.064824              0.041808        0.073595  \n",
       "schoolsup          0.000000              0.000000        0.041681  \n",
       "studytime          0.064011              0.041000        0.000000  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([feature_choose_compare_2,feature_choose_compare], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36256564085685\n",
      "2.0886755709915437\n",
      "0.2300313029074198\n"
     ]
    }
   ],
   "source": [
    "x = data_train_reg_2[feature_choose_forest_2]\n",
    "y = data_train_reg_2[\"G3\"]\n",
    "test_x = data_test_reg_2[feature_choose_forest_2]\n",
    "test_y = data_test_reg_2[\"G3\"]\n",
    "random_regression = RandomForestRegressor(max_depth = 5, n_estimators = 300)\n",
    "random_regression.fit(x, y)\n",
    "random_pred_y = random_regression.predict(test_x)\n",
    "print(mean_squared_error(test_y, random_pred_y))\n",
    "print(math.sqrt(mean_squared_error(test_y, random_pred_y)))\n",
    "print(r2_score(test_y, random_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.142273715904077\n",
      "2.2676582008548105\n",
      "0.09241714186553307\n"
     ]
    }
   ],
   "source": [
    "x = data_train_reg_2[feature_choose_gradient_2]\n",
    "y = data_train_reg_2[\"G3\"]\n",
    "test_x = data_test_reg_2[feature_choose_gradient_2]\n",
    "test_y = data_test_reg_2[\"G3\"]\n",
    "grad_regression = GradientBoostingRegressor(learning_rate = 0.01, n_estimators = 1000, max_depth =5)\n",
    "grad_regression.fit(x, y)\n",
    "grad_pred_y = grad_regression.predict(test_x)\n",
    "print(mean_squared_error(test_y, grad_pred_y))\n",
    "print(math.sqrt(mean_squared_error(test_y, grad_pred_y)))\n",
    "print(r2_score(test_y, grad_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.18094865432652\n",
      "4.81465976516789\n",
      "-3.091309174945996\n"
     ]
    }
   ],
   "source": [
    "x = data_train_reg_2[feature_choose_xgb_2]\n",
    "y = data_train_reg_2[\"G3\"]\n",
    "test_x = data_test_reg_2[feature_choose_xgb_2]\n",
    "test_y = data_test_reg_2[\"G3\"]\n",
    "xgb_regression = XGBRegressor(learning_rate = 0.01, alpha = 0.1, max_depth = 5)\n",
    "xgb_regression.fit(x, y)\n",
    "xgb_pred_y = xgb_regression.predict(test_x)\n",
    "print(mean_squared_error(test_y, xgb_pred_y))\n",
    "print(math.sqrt(mean_squared_error(test_y, xgb_pred_y)))\n",
    "print(r2_score(test_y, xgb_pred_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
